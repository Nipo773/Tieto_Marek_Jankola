{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X and O classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by loading dataset. I took some pictuers of X and O written on paper by pen. Then I generated some modifications of that pictures resulting in dataset containing 3645 samples in `XOtrain` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "data = np.array([])\n",
    "for i in range(7,3652):\n",
    "    image = np.array(Image.open(\"X_and_O/XOtrain/\" + str(i) + \".jpg\").resize((28,28)))\n",
    "    data = np.append(data, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reshape(3645, 28, 28, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = np.concatenate((data[0:123], data[246:1640], data[2050:2091], data[2501:2542], data[2952:2993], data[3403:3444]))\n",
    "data_O = np.concatenate((data[123:246], data[1640:2050], data[2091:2501], data[2542:2952], data[2993:3403], data[3444:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I divided pictures to two arrays and added labels to them. Let's devide them to training data and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X_train = data_X[:1500]\n",
    "data_X_test = data_X[1500:]\n",
    "data_O_train = data_O[:1500]\n",
    "data_O_test = data_O[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_y = np.array([1 for i in range(len(data_X_train))] + [0 for i in range(len(data_O_train))])\n",
    "data_test_y = np.array([1 for i in range(len(data_X_test))] + [0 for i in range(len(data_O_test))])\n",
    "data_train_X = np.concatenate((data_X_train, data_O_train))\n",
    "data_test_X = np.concatenate((data_X_test, data_O_test))\n",
    "data_train_y = to_categorical(data_train_y)\n",
    "data_test_y = to_categorical(data_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we have our data ready, let's choose a model. For binary picture classification is the best choice convolutional neural network. We will build few convolutional layers for picture preprocessing and then few NN layers for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "3000/3000 [==============================] - 2s 744us/step - loss: 2.0254 - accuracy: 0.5973\n",
      "Epoch 2/8\n",
      "3000/3000 [==============================] - 2s 635us/step - loss: 0.4085 - accuracy: 0.8187\n",
      "Epoch 3/8\n",
      "3000/3000 [==============================] - 2s 642us/step - loss: 0.2247 - accuracy: 0.91100s - loss:\n",
      "Epoch 4/8\n",
      "3000/3000 [==============================] - 2s 637us/step - loss: 0.1273 - accuracy: 0.9543\n",
      "Epoch 5/8\n",
      "3000/3000 [==============================] - 2s 602us/step - loss: 0.1346 - accuracy: 0.9527\n",
      "Epoch 6/8\n",
      "3000/3000 [==============================] - 2s 601us/step - loss: 0.1116 - accuracy: 0.9657\n",
      "Epoch 7/8\n",
      "3000/3000 [==============================] - 2s 601us/step - loss: 0.0805 - accuracy: 0.9707\n",
      "Epoch 8/8\n",
      "3000/3000 [==============================] - 2s 597us/step - loss: 0.0607 - accuracy: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a0bcafe490>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(data_train_X, data_train_y, epochs=8, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we trained our model let's evaluate it. Let's make confusion matrix and compute accuracy on testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(data_test_X)\n",
    "pred_y_labels = np.argmax(pred_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix\n",
      "[[452  12]\n",
      " [  0 181]]\n",
      "\n",
      "Classification Report\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9813953488372092"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "true_y_labels = np.argmax(data_test_y, axis=1)\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(confusion_matrix(true_y_labels, pred_y_labels))\n",
    "print(\"\\nClassification Report\")\n",
    "target_names = [str(i) for i in range(2)]\n",
    "count = 0\n",
    "for i in range(len(true_y_labels)):\n",
    "    if true_y_labels[i] == pred_y_labels[i]:\n",
    "        count += 1\n",
    "count/len(true_y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see convolutional NN was very good choice, we reached approximately 98% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find application source code in `X_and_O` folder. It takes one positional argument of possible output (possible extension to save image you took by it). As I didn't added the extension yet don't be confused by useless argument. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can execute application by terminal. Open the folder `X_and_O` (which contains all the source code you need and training set) and execute exactly this command: `python XOclassifier.py --output output`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give it about 2 minutes because application has to train the model and run your webcam. In application you just need to put X or O written on paper (it would be best if you wrote it by blue pen, because training set was build on the letters written by blue pen) in the front of your camera. Then click the button `Snapshot!`. On the right corner should pop off the window with the final classification of your photo. You can take more photos if you want, application is properly running until you turn it off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned before, the best model for such task is convolutional NN. As we can see it is performing really good on testing dataset. I experienced some imperfections though, during testing the application. They were mainly caused because I used pictures with X or O written by some different pen or captured by different angles. This can be fixed by altering training dataset and adding more different photos in it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see potentional improvements mainly in data preprocessing with more time we could add data augmentation before entering the model. CNN `fit_generate` might be better than my `generator` as well so that is another possible way of improvement. Another idea that came to my mind is the in application I could use some existing trained model saved somewhere so it wouldn't load so long in the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope that you like my work on this task and thank you for this opportunity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marek Jankola"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
